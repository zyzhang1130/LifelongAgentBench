default:
  module: "src.language_models.instance.huggingface_language_model.HuggingfaceLanguageModel"
  parameters:
    role_dict:
      user: "user"
      agent: "assistant"
    dtype: "bfloat16"
    device_map: "niuload"

Llama-3.1-8B-Instruct:
  parameters:
    model_name_or_path: "/mnt/pfs_l2/jieti_team/MMGroup/lzz/huggingface_checkpoint/Llama-3.1-8B-Instruct"

DeepSeek-R1-Distill-Llama-8B:
  parameters:
    model_name_or_path: "/mnt/pfs_l2/jieti_team/MMGroup/lzz/huggingface_checkpoint/DeepSeek-R1-Distill-Llama-8B"

Qwen2.5-7B-Instruct:
  parameters:
    model_name_or_path: "/mnt/pfs_l2/jieti_team/MMGroup/lzz/huggingface_checkpoint/Qwen2.5-7B-Instruct"

DeepSeek-R1-Distill-Qwen-7B:
  parameters:
    model_name_or_path: "/mnt/pfs_l2/jieti_team/MMGroup/lzz/huggingface_checkpoint/DeepSeek-R1-Distill-Qwen-7B"

Qwen2.5-32B-Instruct:
  parameters:
    model_name_or_path: "/mnt/pfs_l2/jieti_team/MMGroup/lzz/huggingface_checkpoint/Qwen2.5-32B-Instruct"

QwQ-32B:
  parameters:
    model_name_or_path: "/mnt/pfs_l2/jieti_team/MMGroup/lzz/huggingface_checkpoint/QwQ-32B"

Llama-3.1-70B-Instruct:
  parameters:
    model_name_or_path: "/mnt/pfs_l2/jieti_team/MMGroup/lzz/huggingface_checkpoint/Llama-3.1-70B-Instruct"

DeepSeek-R1-Distill-Llama-70B:
  parameters:
    model_name_or_path: "/mnt/pfs_l2/jieti_team/MMGroup/lzz/huggingface_checkpoint/DeepSeek-R1-Distill-Llama-70B"

Qwen2.5-72B-Instruct:
  parameters:
    model_name_or_path: "/mnt/pfs_l2/jieti_team/MMGroup/lzz/huggingface_checkpoint/Qwen2.5-72B-Instruct"

DeepSeek-R1-Distill-Qwen-32B:
  parameters:
    model_name_or_path: "/mnt/pfs_l2/jieti_team/MMGroup/lzz/huggingface_checkpoint/DeepSeek-R1-Distill-Qwen-32B"

#generation_config_dict:
#  # https://huggingface.co/docs/transformers/v4.47.1/en/main_classes/text_generation#transformers.GenerationConfig.generation_kwargs
#  # Greedy decoding
#  do_sample: false
#  num_beams: 1
#  max_new_tokens: 512  # The same as AgentBench
#  temperature: ~
#  top_p: ~